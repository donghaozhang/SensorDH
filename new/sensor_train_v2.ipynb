{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch as tf\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tools import load_sensor_data_without_h, sample_sensor_data, manual_lable_array_list, most_frequent, extract_sensor_data, get_sensor_data, sample_data, sample_label, combine_to_one\n",
    "from model import Classifier_dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_to_label = {'talk':0, 'eat':1, 'read':2, 'drink':3, 'computer':4, 'write':5, 'other': 6}\n",
    "actor_1 = [1,2,3,4,5,6,7,8,9,10]\n",
    "actor_2 = [11,12,13,14,31,32,33,34,35,36]\n",
    "actor_3 = [15,16,17,18,37,38,39,40,41,42]\n",
    "actor_4 = [43,44,45,46,47,48,49,50,51,52]\n",
    "actor_5 = [53,54,55,56,57,58,59,60,61,62]\n",
    "actor_6 = [63,64,65,66,67,68,69,70,71,72]\n",
    "actor_7 = [76,77,78,79,80,81,82,83,84,85]\n",
    "actor_8 = [86,87,88,89,90,91,92,93,94,95]\n",
    "actor_9 = [97,98,99,100,101,102,103,104,105,106]\n",
    "actor_10 = [107,108,109,110,111,112,113,114,115,116]\n",
    "actor_11 = [117,118,119,120,121,122,123,124,125,126]\n",
    "actor_12 = [128,129,130,131,132,133,134,135,136,137]\n",
    "actor_13 = [138,139,140,141,142,143,144,145,146,147]\n",
    "actor_14 = [148,149,150,151,152,153,154,155,156,157]\n",
    "actor_15 = [161,162,163,164,165,166,167,168,169,170]\n",
    "actor_16 = [171,172,173,174,175,176,177,178,179,180]\n",
    "actor_17 = [181,182,183,184,185,186,187,188,189,190]\n",
    "actor_18 = [191,192,193,194,195,196,197,198,199,200]\n",
    "actor_19 = [201,202,203,204,205,206,207,208,209,210]\n",
    "actor_20 = [212,213,214,215,216,217,218,219,220,221]\n",
    "actor_21 = [223,224,225,226,227,228,229,230,231,232]\n",
    "actor_22 = [233,234,235,236,237,238,239,240,241,242]\n",
    "actor_23 = [243,244,245,246,247,248,249,250,251,252]\n",
    "actor_24 = [254,255,256,257,258,259,260,261,262,263]\n",
    "actor_25 = [264,265,266,267,268,269,270,271,272,273]\n",
    "combine_list = actor_1 + actor_2 + actor_3 + actor_4 + actor_5 + actor_6 + actor_7 + actor_8 + actor_9 + actor_10+ actor_11 + actor_12 + actor_13 + actor_14 + actor_15+ actor_16 + actor_17 + actor_18 + actor_19 + actor_20+ actor_21 + actor_22 + actor_23 + actor_24 + actor_25\n",
    "window_sz = 128\n",
    "sample_sz = 128\n",
    "lr = 0.001\n",
    "n_epochs = 500\n",
    "num_classes = 6\n",
    "patience, trials = 100, 0\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "bs = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual_lable_array_list('../manual_lable.csv', combine_list)\n",
    "#extract_sensor_data(combine_list) \n",
    "\n",
    "#label_list = np.load('../save_data/label_data/label_list.npy', allow_pickle=True).item()\n",
    "#sensor_data = get_sensor_data('../save_data/original_data/')\n",
    "\n",
    "#sample_data(sensor_data, combine_list, window_sz = window_sz, sample_sz = sample_sz)\n",
    "#sample_label(label_list, combine_list, window_sz = window_sz, sample_sz = sample_sz)\n",
    "   \n",
    "sample_sensor_data = get_sensor_data('../save_data/sample_data/')\n",
    "sample_sensor_label = get_sensor_data('../save_data/sample_label/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_list = total_num_list = actor_1 + actor_2 + actor_3 + actor_4+actor_5+actor_6+actor_7+actor_8+actor_9+actor_10+actor_11+actor_12+actor_13+actor_14+actor_15+actor_16+actor_17+actor_18+actor_19+actor_20+actor_21+actor_22+actor_23+actor_24+actor_25\n",
    "val_num_list = total_num_list[1*10 : 1*10+10]\n",
    "del total_num_list[1*10 : 1*10+10]\n",
    "train_num_list = total_num_list\n",
    "train_sensor_data = combine_to_one(sample_sensor_data,train_num_list)\n",
    "val_sensor_data = combine_to_one(sample_sensor_data,val_num_list)\n",
    "train_sensor_label = combine_to_one(sample_sensor_label,train_num_list)\n",
    "val_sensor_label = combine_to_one(sample_sensor_label,val_num_list)\n",
    "train_ds = TensorDataset(torch.tensor(train_sensor_data).float(), torch.tensor(train_sensor_label).long())\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "val_ds = TensorDataset(torch.tensor(val_sensor_data).float(), torch.tensor(val_sensor_label).long())\n",
    "val_dl = DataLoader(val_ds, batch_size=bs, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(torch.tensor(train_sensor_data).float(), torch.tensor(train_sensor_label).long())\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "val_ds = TensorDataset(torch.tensor(val_sensor_data).float(), torch.tensor(val_sensor_label).long())\n",
    "val_dl = DataLoader(val_ds, batch_size=bs, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"Very simple implementation of LSTM-based time-series classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batch_size = None\n",
    "        self.hidden = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        return [t.cuda() for t in (h0, c0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch 1 best model saved with accuracy: 34.52%\n",
      "Epoch 3 best model saved with accuracy: 39.43%\n",
      "Epoch:   5. Loss: 47.4997. Acc.: 24.91%\n",
      "Epoch:  10. Loss: 56.8568. Acc.: 33.27%\n",
      "Epoch:  15. Loss: 34.9258. Acc.: 28.43%\n",
      "Epoch:  20. Loss: 18.9336. Acc.: 36.58%\n",
      "Epoch:  25. Loss: 4.6144. Acc.: 31.92%\n",
      "Epoch:  30. Loss: 9.2812. Acc.: 34.34%\n",
      "Epoch:  35. Loss: 11.4466. Acc.: 32.35%\n",
      "Epoch:  40. Loss: 4.0585. Acc.: 41.17%\n",
      "Epoch 40 best model saved with accuracy: 41.17%\n",
      "Epoch:  45. Loss: 8.7170. Acc.: 33.49%\n",
      "Epoch:  50. Loss: 5.7565. Acc.: 33.81%\n",
      "Epoch:  55. Loss: 3.9265. Acc.: 32.92%\n",
      "Epoch:  60. Loss: 5.8446. Acc.: 29.68%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c551d8e8e8f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dim = 39   \n",
    "hidden_dim = 256\n",
    "layer_dim = 3\n",
    "output_dim = 6\n",
    "seq_dim = 128\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs = 1000\n",
    "iterations_per_epoch = len(train_dl)\n",
    "best_acc = 0\n",
    "patience, trials = 100, 0\n",
    "\n",
    "model = LSTMClassifier(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "sched = CyclicLR(opt, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/100))\n",
    "\n",
    "print('Start model training')\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(train_dl):\n",
    "        model.train()\n",
    "        x_batch = x_batch.cuda()\n",
    "        y_batch = y_batch.cuda()\n",
    "        y_batch = tf.squeeze(y_batch)\n",
    "        #sched.step()\n",
    "        opt.zero_grad()\n",
    "        out = model(x_batch)\n",
    "        #print(out.shape)\n",
    "        #print(y_batch.shape)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for x_val, y_val in val_dl:\n",
    "        x_val, y_val = [t.cuda() for t in (x_val, y_val)]\n",
    "        y_val = tf.squeeze(y_val)\n",
    "        out = model(x_val)\n",
    "        preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "        total += y_val.size(0)\n",
    "        correct += (preds == y_val).sum().item()\n",
    "    \n",
    "    acc = correct / total\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch: {epoch:3d}. Loss: {loss.item():.4f}. Acc.: {acc:2.2%}')\n",
    "\n",
    "    if acc > best_acc:\n",
    "        trials = 0\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'best.pth')\n",
    "        print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "    else:\n",
    "        trials += 1\n",
    "        if trials >= patience:\n",
    "            print(f'Early stopping on epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "Epoch 1 best model saved with accuracy: 26.33%\n",
      "Epoch 2 best model saved with accuracy: 33.91%\n",
      "Epoch 7 best model saved with accuracy: 34.06%\n",
      "Epoch 8 best model saved with accuracy: 34.45%\n",
      "Epoch:  10. Loss: 53380.4737. Acc.: 34.70%\n",
      "Epoch 10 best model saved with accuracy: 34.70%\n",
      "Epoch 11 best model saved with accuracy: 37.47%\n",
      "Epoch:  20. Loss: 43439.9625. Acc.: 36.41%\n",
      "Epoch:  30. Loss: 39022.7170. Acc.: 34.38%\n",
      "Epoch:  40. Loss: 36165.1663. Acc.: 33.13%\n",
      "Epoch:  50. Loss: 34818.9941. Acc.: 34.20%\n",
      "Epoch:  60. Loss: 33508.0131. Acc.: 37.05%\n",
      "Epoch:  70. Loss: 32642.9418. Acc.: 34.52%\n",
      "Epoch:  80. Loss: 31990.1024. Acc.: 35.12%\n",
      "Epoch:  90. Loss: 31362.4975. Acc.: 33.49%\n",
      "Epoch: 100. Loss: 30761.7552. Acc.: 34.38%\n",
      "Epoch: 110. Loss: 30452.2671. Acc.: 34.20%\n",
      "Early stopping on epoch 111\n"
     ]
    }
   ],
   "source": [
    "bestacc = []\n",
    "for actor in range(24,25):\n",
    "    total_num_list = total_num_list = actor_1 + actor_2 + actor_3 + actor_4+actor_5+actor_6+actor_7+actor_8+actor_9+actor_10+actor_11+actor_12+actor_13+actor_14+actor_15+actor_16+actor_17+actor_18+actor_19+actor_20+actor_21+actor_22+actor_23+actor_24+actor_25\n",
    "    val_num_list = total_num_list[actor*10 : actor*10+10]\n",
    "    del total_num_list[actor*10 : actor*10+10]\n",
    "    train_num_list = total_num_list\n",
    "    train_sensor_data = combine_to_one(sample_sensor_data,train_num_list)\n",
    "    val_sensor_data = combine_to_one(sample_sensor_data,val_num_list)\n",
    "    train_sensor_label = combine_to_one(sample_sensor_label,train_num_list)\n",
    "    val_sensor_label = combine_to_one(sample_sensor_label,val_num_list)\n",
    "    model = Classifier_dh(train_sensor_data.shape[1], train_sensor_data.shape[2], num_classes).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_ds = TensorDataset(torch.tensor(train_sensor_data).float(), torch.tensor(train_sensor_label).long())\n",
    "    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "    val_ds = TensorDataset(torch.tensor(val_sensor_data).float(), torch.tensor(val_sensor_label).long())\n",
    "    val_dl = DataLoader(val_ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "    best_acc = 0\n",
    "    loss_history = []\n",
    "    acc_history = []\n",
    "    print('Start model training')\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for i, batch in enumerate(train_dl):\n",
    "            x_raw, y_batch = [t.to(device) for t in batch]\n",
    "            y_batch = tf.squeeze(y_batch)\n",
    "            opt.zero_grad()\n",
    "            out = model(x_raw)\n",
    "            loss = criterion(out, y_batch)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        loss_history.append(epoch_loss)\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        for batch in val_dl:\n",
    "            x_raw, y_batch = [t.to(device) for t in batch]\n",
    "            y_batch = tf.squeeze(y_batch)\n",
    "            out = model(x_raw)\n",
    "            preds = F.log_softmax(out, dim=1).argmax(dim=1)\n",
    "            if preds.size()[0] > 1:\n",
    "                total += y_batch.size(0)\n",
    "                correct += (preds == y_batch).sum().item()\n",
    "        acc = correct / total\n",
    "        acc_history.append(acc)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch:3d}. Loss: {epoch_loss:.4f}. Acc.: {acc:2.2%}')\n",
    "        if acc > best_acc:\n",
    "            trials = 0\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), 'best.pth')\n",
    "            print(f'Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}')\n",
    "        else:\n",
    "            trials += 1\n",
    "            if trials >= patience:\n",
    "                print(f'Early stopping on epoch {epoch}')\n",
    "                break\n",
    "    bestacc.append(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3747330960854093]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[39.86, 54.80, 67.65, 44.23, 69.04, 65.87, 70.82, 53.27, 51.71, 69.40, 68.90, 59.82, 56.69, 69.07, 62.38, 60.32, 56.98, 73.74, 51.07, 64.84, 58.97, 51.25, 48.26, 52.63, 37.47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.361599999999996"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(A)/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[54.80, 67.65, 44.23, 69.04, 65.87, 70.82, 53.27, 51.71, 69.40, 68.90, 59.82, 56.69, 69.07, 62.38, 60.32, 56.98, 73.74, 51.07, 64.84, 58.97, 51.25, 48.26, 52.63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.07434782608696"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(A)/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
